{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5ab21361b3c3efaa1d00ba5cc7fe603826b95878"
      },
      "cell_type": "markdown",
      "source": "### Review of Pandas\n\nYou can find at here : What can we de with Pandas library.\nI included these subjects to kernel :\n* Review of Pandas\n* Building data frames form scratch\n* Visual exploratory data analysis\n* Statictical exploratory data analysis\n* Indexing Pandas time series\n* Resampling Pandas time series"
    },
    {
      "metadata": {
        "_uuid": "fd2546ea99ce367538dbedd3d1c0ea9a2bf6b547"
      },
      "cell_type": "markdown",
      "source": "As you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy"
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['2017.csv', '2016.csv', '2015.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "### BUILDING DATA FRAMES FROM SCRATCH\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n    * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "14d3cef7ad78f94659993feef36bbbd05bc5a982"
      },
      "cell_type": "code",
      "source": "country = ['Turkey', 'Germany']#values\npopulation = ['80000000', '65000000']#values\nlist_label = ['country', 'population']#column names\nlist_column = [country, population]#values have relation with columns \nzipped = list(zip(list_label,list_column))#mwe used zip() method for creating a table form\ndata_dict = dict(zipped)#zip() method returns tuple data type. We have to change it to dictionary for using with Pandas\ndata = pd.DataFrame(data_dict)#dictionary transformed into Data Frame.\ndata",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "68ed7b3bc380c0b0f6ae6ecd2a27d44c42afe190"
      },
      "cell_type": "markdown",
      "source": "I have added a new column to data frame."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5eb4e0a0d2c4d2a3d53727317fef62c068ee0f3d"
      },
      "cell_type": "code",
      "source": "data['capital'] = ['Ankara', 'Berlin']\ndata",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "97d9b94205c946bff8fdecd170dfe86b102d06a8"
      },
      "cell_type": "markdown",
      "source": "What is broadcasting ?\n\nBroadcasting is, adding a new column and giving a value. And it works like map function. Broadcasting the value to all data.  "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c6963534ef8387d2cea2d574a07facd27ecfaba1"
      },
      "cell_type": "code",
      "source": "data['test'] = '123'\ndata",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8e12216bafddd7832389ec727e755761f3e00938"
      },
      "cell_type": "markdown",
      "source": "### VISUAL EXPLORATORY DATA ANALYSIS\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "60fb405545c49e113448694af6a4ede781c5c0dd"
      },
      "cell_type": "code",
      "source": "data1 = pd.read_csv('../input/2017.csv') #creating new data frame from World Happiness Report dataset.\ndata1.head()\ndata1_cols = data1.columns\ndata1_cols = data1_cols.str.replace('.','_')\ndata1.columns = data1_cols\ndata1.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "785c1bc34a8aec68f1bfa126e0e6d71f87672dd7"
      },
      "cell_type": "code",
      "source": "data2 = data1.loc[:,['Happiness_Rank', 'Family', 'Freedom']]\ndata2.plot()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2a0a96fa061bb85237659a375b9a77f351d17123"
      },
      "cell_type": "markdown",
      "source": "I have plotted but it is meaningless. Therefore I am using subplots."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d960223ecf29cf38abe492758549c2faf6587143"
      },
      "cell_type": "code",
      "source": "data2.plot(subplots = True, figsize= (12,12))\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "75c8934a835c3b8ad2d9c8f3ddf25c49544edbb7"
      },
      "cell_type": "code",
      "source": "data2.plot(kind='scatter', x= 'Happiness_Rank', y='Freedom', color = 'Red',grid = True, alpha=0.5, figsize = (12,12))\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ebb0e59cd834470d4ba2789428e13c331d7e5008"
      },
      "cell_type": "markdown",
      "source": "I am plotting histogram figure. I am using normed and range parameters this time. \n* Range is used for limiting x-axis. At this example, I have limited Happiness Rank values in-between 0-250.\n* Density is used for formalizating y-label in between 0-1. At this example, I have formalized frequency value of Happiness Rank column."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1f6acefb8f1b623dc40c96c6b97804fb2c238fea"
      },
      "cell_type": "code",
      "source": "data2.plot(kind='hist', y= 'Happiness_Rank', bins = 50, range=(0,250), density=True)\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3fccdfed317a599a761cd86494050a7160077535"
      },
      "cell_type": "code",
      "source": "fig,axes = plt.subplots(nrows=2 , ncols=1)\ndata2.plot(kind='hist', y='Freedom', bins = 50, range=(0,1), density=True, ax= axes[0])\ndata2.plot(kind='hist', y='Happiness_Rank', bins= 50, range=(0,250), density=True, ax=axes[1], cumulative = True)\nplt.savefig('graph.png')\nplt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bef3a458ca5cd2c72ed66066c62e12e9eafdcc10"
      },
      "cell_type": "markdown",
      "source": "There is an example of how to use ' cumulative ' parameter. This parameter works like fibonnaci . For each value, sums each value before it and returns result of sum."
    },
    {
      "metadata": {
        "_uuid": "8793c294341ed14a1448ccaa4f1ae9ac7798bf79"
      },
      "cell_type": "markdown",
      "source": "### STATISTICAL EXPLORATORY DATA ANALYSIS\nI already explained it at previous parts. However lets look at one more time.\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e4d58a267038245d1c4c44b9f976aef62e3a3f4c"
      },
      "cell_type": "code",
      "source": "data1.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "46719f4690c541536845103ceaf65ad775c2cb04"
      },
      "cell_type": "markdown",
      "source": "### INDEXING PANDAS TIME SERIES\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ed5331b1501fa4745454e1bc679581fe2dfc7aa"
      },
      "cell_type": "code",
      "source": "time_list=[\"1995-04-23\",\"1999-11-14\",\"1989-1-17\",\"1996-6-5\",\"1999-11-4\"]\nprint(type(time_list[1]))#returns string\n# lets convert it to datetime object\ndata3 = data2.head()\ndatetime_object = pd.to_datetime(time_list)#converting process to datetime\ndata3['date'] = datetime_object#adding to dataframe as a column\ndata3",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6862f56798e603b93abb7ced4b017d74f4279454"
      },
      "cell_type": "markdown",
      "source": "Lets drop the index values and creating a new index from datetime list."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f00088bfaaff6b480e5e79421ddfc778771c0236"
      },
      "cell_type": "code",
      "source": "data3 = data3.set_index('date')\ndata3",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "64c11917cd21e013b61e4a7785b519c04c08c203"
      },
      "cell_type": "markdown",
      "source": "I am selecting data using time index."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "027a68659d87a914e69f6753c833cc9015308033"
      },
      "cell_type": "code",
      "source": "print(data3.loc['1999-11-14'])\nprint(data3.loc['1989-01-17':'1999-11-04'])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d41dcb14bc103826034018ef6955b64beffa15da"
      },
      "cell_type": "markdown",
      "source": "### RESAMPLING PANDAS TIME SERIES\n* Resampling: statistical method over different time intervals\n    * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like ‘linear’, ‘time’ or index’ \n    * https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.interpolate.html"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5eee7350552d907ad1b381f8184e15bfbd41a5e0"
      },
      "cell_type": "code",
      "source": "data3.resample('A').mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c3c78c1708016d7e481873843dd1b080b58704e0"
      },
      "cell_type": "markdown",
      "source": "At here, I resample by year (using ' A '). Showing values from dataframe, and putting NaN values for not found values in dataframe."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4bf5e962960ceab20707a88777407a673f5d4259"
      },
      "cell_type": "code",
      "source": "data3.resample('M').mean()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0cc85f28fb91d8d0b6a6d2cab5b281eb5a3eaf28"
      },
      "cell_type": "markdown",
      "source": "I resample by months (using ' M '). Showing values from dataframe, and putting NaN values for not found values in dataframe."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "31d45d0990f66a95ed573eee5c5aaf2b4ec9ea9d"
      },
      "cell_type": "code",
      "source": "data3.resample('M').first().interpolate('linear')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "73b2383f812b3dab207672a6f582fd550b3e0d16"
      },
      "cell_type": "markdown",
      "source": "Interpolate method fills the NaN values with values between the highest and the lowest index.\nThere is another example of resampling : "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a392675defa2dc26e4874b3f80cb4cb4376db011"
      },
      "cell_type": "code",
      "source": "data3.resample(\"M\").mean().interpolate(\"linear\")",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}